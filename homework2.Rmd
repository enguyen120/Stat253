```{r hw2_setup, include=FALSE}
knitr::opts_chunk$set(echo=TRUE, eval=FALSE)
```

# Homework 2 {-}

<center>
**Due Friday, February 18 at 9:00am CST on [Moodle](https://moodle.macalester.edu/mod/assign/view.php?id=36784)**
</center>

**Deliverables:** Please use [this template](template_rmds/hw2.Rmd) to knit an HTML document. Convert this HTML document to a PDF by opening the HTML document in your web browser. *Print* the document (Ctrl/Cmd-P) and change the destination to "Save as PDF". Submit this one PDF to Moodle.

Alternatively, you may knit your Rmd directly to PDF if you have LaTeX installed.



<br><br><br>




## Project Work {-}

### Instructions {-} 

**Goal:** Begin an analysis of your dataset to answer your **regression** research question.

<br>

**Collaboration:** Form a team (2-3 members) for the project and this part can be done as a team. Only one team member should submit a Project Work section. Make sure you include the full names of all of the members in your write up. 

<br>

**Data cleaning:** If your dataset requires any cleaning (e.g., merging datasets, creation of new variables), first consult the [R Resources page](r-resources.html) to see if your questions are answered there. If not, post on the #rcode-questions channel in our Slack workspace to ask for help. *Please ask for help early and regularly* to avoid stressful workloads.

<br>

### Required Analyses {-}

1. **Initial investigation: ignoring nonlinearity (for now)**
    a. Use ordinary least squares (OLS) by using the `lm` engine and LASSO (`glmnet` engine) to build  a series of initial regression models for your quantitative outcome as a function of the predictors of interest. (As part of data cleaning, exclude any variables that you don't want to consider as predictors.)
        - You'll need two model specifications, `lm_spec` and `lm_lasso_spec` (you'll need to tune this one).
    b. For each set of variables, you'll need a `recipe` with the `formula`, `data`, and pre-processing steps
        - You may want to have steps in your recipe that remove variables with near zero variance (`step_nzv()`), remove variables that are highly correlated with other variables (`step_corr()`), normalize all quantitative predictors (`step_normalize(all_numeric_predictors())`) and add indicator variables for any categorical variables (`step_dummy(all_nominal_predictors())`).
        - These models should not include any transformations to deal with nonlinearity. You'll explore this in the next investigation.
    c. Estimate the test performance of the models using CV. Report and interpret (with units) the CV metric estimates along with a measure of uncertainty in the estimate (`std_error` is readily available when you used `collect_metrics(summarize=TRUE)`).
        - Compare estimated test performance across the models. Which models(s) might you prefer?
    d. Use residual plots to evaluate whether some quantitative predictors might be better modeled with nonlinear relationships.
    e. Which variables do you think are the most important predictors of your quantitative outcome? Justify your answer. Do the methods you've applied reach consensus on which variables are most important? What insights are expected? Surprising?
        - Note that if some (but not all) of the indicator terms for a categorical predictor are selected in the final models, the whole predictor should be treated as selected.

<br>

#### Your Work {-}

a & b.

```{r}
library(dplyr)
library(ggplot2)
library(readr)
library(lubridate)
library(astsa)
library(splines)
library(tidymodels)
tidymodels_prefer()
```

```{r}
health <- read_csv("worldbank.csv")
```
```{r}
health <- health %>%
  filter(`2018 [YR2018]`!="..") %>%
  filter(`Country Code` !="VIR") %>%
  filter(`Country Code` !="ABW") %>%
  filter(`Country Code` !="ASM") %>%
  filter(`Country Code` !="CHI") %>%
  filter(`Country Code` !="CUW") %>%
  filter(`Country Code` !="FRO") %>%
  filter(`Country Code` !="PYF") %>%
  filter(`Country Code` !="GUM") %>%
  filter(`Country Code` !="HKG") %>%
  filter(`Country Code` !="IMM") %>%
  filter(`Country Code` !="LIE") %>%
  filter(`Country Code` !="MAC") %>%
  filter(`Country Code` !="MHL") %>%
  filter(`Country Code` !="NRU") %>%
  filter(`Country Code` !="NCL") %>%
  filter(`Country Code` !="SST") %>%
  filter(`Country Code` !="PRE") %>%
  filter(`Country Code` !="SAS") %>%
  filter(`Country Code` !="WLD") %>%
  filter(`Country Code` !="UMC") %>%
  filter(`Country Code` !="TSS") %>%
  filter(`Country Code` !="SSA") %>%
  filter(`Country Code` !="SSF") %>%
  filter(`Country Code` !="ASM") %>%
  filter(`Country Code` !="TSA") %>%
  filter(`Country Code` !="PST") %>%
  filter(`Country Code` !="MNP") %>%
  filter(`Country Code` !="PSS") %>%
  filter(`Country Code` !="OSS") %>%
  filter(`Country Code` !="OED") %>%
  filter(`Country Code` !="NAC") %>%
  filter(`Country Code` !="INX") %>%
  filter(`Country Code` !="SMR") %>%
  filter(`Country Code` !="MIC") %>%
  filter(`Country Code` !="TMN") %>%
  filter(`Country Code` !="SXM") %>%
  filter(`Country Code` !="MNA") %>%
  filter(`Country Code` !="MEA") %>%
  filter(`Country Code` !="LMC") %>%
  filter(`Country Code` !="LIC") %>%
  filter(`Country Code` !="LMY") %>%
  filter(`Country Code` !="LDC") %>%
  filter(`Country Code` !="TLA") %>%
  filter(`Country Code` !="LAC") %>%
  filter(`Country Code` !="KNA") %>%
  filter(`Country Code` !="MAF") %>%
  filter(`Country Code` !="LCN") %>%
  filter(`Country Code` !="LTE") %>%
  filter(`Country Code` !="IDA") %>%
  filter(`Country Code` !="IDX") %>%
  filter(`Country Code` !="IDV") %>%
  filter(`Country Code` !="TCA") %>%
  filter(`Country Code` !="IBT") %>%
  filter(`Country Code` !="IBD") %>%
  filter(`Country Code` !="HIC") %>%
  filter(`Country Code` !="TUV") %>%
  filter(`Country Code` !="HPC") %>%
  filter(`Country Code` !="FCS") %>%
  filter(`Country Code` !="EUU") %>%
  filter(`Country Code` !="TEC") %>%
  filter(`Country Code` !="ECA") %>%
  filter(`Country Code` !="ECS") %>%
  filter(`Country Code` !="EMU") %>%
  filter(`Country Code` !="TEA") %>%
  filter(`Country Code` !="EAP") %>%
  filter(`Country Code` !="EAS") %>%
  filter(`Country Code` !="EAR") %>%
  filter(`Country Code` !="CEB") %>%
  filter(`Country Code` !="CSS") %>%
  filter(`Country Code` !="ARB") %>%
  filter(`Country Code` !="AFW") %>%
  filter(`Country Code` !="AFE") %>%
  filter(`Country Code` !="AND") %>%
  filter(`Country Code` !="BMU") %>%
  filter(`Country Code` !="CYM") %>%
  filter(`Country Code` !="DMA") %>%
  filter(`Country Code` !="ERI") %>%
  filter(`Country Code` !="GRL") %>%
  filter(`Country Code` !="IMN") %>%
  filter(`Country Code` !="LBY") %>%
  filter(`Country Code` !="MCO") %>%
  filter(`Country Code` !="PLW") %>%
  filter(`Country Code` !="PRI") %>%
  filter(`Country Code` !="PRK") %>%
  filter(`Country Code` !="PSE") %>%
  filter(`Country Code` !="SOM") %>%
  filter(`Country Code` !="SSD") %>%
  filter(`Country Code` !="SYR") %>%
  filter(`Country Code` !="VEN") %>%
  filter(`Country Code` !="XKX") %>%
  filter(`Country Code` !="YEM") %>%
  filter(`Country Code` !="IDB")
```

```{r}
lifeExpectancyData <- health %>%
  select(-`Series Code`) %>%
  select(-`1990 [YR1990]`) %>%
  select(-`1991 [YR1991]`) %>%
  select(-`1992 [YR1992]`) %>%
  select(-`1993 [YR1993]`) %>%
  select(-`1994 [YR1994]`) %>%
  select(-`1995 [YR1995]`) %>%
  select(-`1996 [YR1996]`) %>%
  select(-`1997 [YR1997]`) %>%
  select(-`1998 [YR1998]`) %>%
  select(-`1999 [YR1999]`) %>%
  select(-`2000 [YR2000]`) %>%
  select(-`2001 [YR2001]`) %>%
  select(-`2002 [YR2002]`) %>%
  select(-`2003 [YR2003]`) %>%
  select(-`2004 [YR2004]`) %>%
  select(-`2005 [YR2005]`) %>%
  select(-`2006 [YR2006]`) %>%
  select(-`2007 [YR2007]`) %>%
  select(-`2008 [YR2008]`) %>%
  select(-`2009 [YR2009]`) %>%
  select(-`2010 [YR2010]`) %>%
  select(-`2011 [YR2011]`) %>%
  select(-`2012 [YR2012]`) %>%
  select(-`2013 [YR2013]`) %>%
  select(-`2014 [YR2014]`) %>%
  select(-`2015 [YR2015]`) %>%
  select(-`2016 [YR2016]`) %>%
  select(-`2017 [YR2017]`) %>%
  select(-`2019 [YR2019]`) %>%
  select(-`2020 [YR2020]`) 
```

```{r}
lifeExpectancy<- pivot_wider(lifeExpectancyData, names_from = "Series Name", values_from = "2018 [YR2018]")
```

```{r}
lifeExpectancy <- lifeExpectancy %>%
  select(-`Life expectancy at birth, female (years)`) %>%
  select(-`Life expectancy at birth, male (years)`) %>%
  select(-`Multidimensional poverty headcount ratio, household (% of total households)`)
```

```{r}
lifeExpectancy <-lifeExpectancy %>%
  rename("country"="Country Name", "country_code"="Country Code", "GDP_per_capita"="GDP per capita (constant 2015 US$)", "GDP"="GDP (constant 2015 US$)", "health_expend"="Current health expenditure (% of GDP)", "life_expec"="Life expectancy at birth, total (years)", "mortality_rate"="Mortality rate, infant (per 1,000 live births)", "domestic_gov_health_expend_% "="Domestic general government health expenditure (% of current health expenditure)","domestic_gov_health_expend_gdp"= "Domestic general government health expenditure (% of GDP)", "domestic_gov_health_expend_per_capita"="Domestic general government health expenditure per capita (current US$)", "ARI_treat"="ARI treatment (% of children under 5 taken to a health provider)", "women_repro"="Women making their own informed decisions regarding sexual relations, contraceptive use and reproductive health care  (% of women age 15-49)",  "women_decision_participation"="Women participating in the three decisions (own health care, major household purchases, and visiting family) (% of women age 15-49)", "poverty_5.50"="Poverty headcount ratio at $5.50 a day (2011 PPP) (% of population)", "poverty_3.20"="Poverty headcount ratio at $3.20 a day (2011 PPP) (% of population)", "poverty_1.90"="Poverty headcount ratio at $1.90 a day (2011 PPP) (% of population)", "prop_25%_plus"="Proportion of population spending more than 25% of household consumption or income on out-of-pocket health care expenditure (%)",  "gini_index"= "Gini index (World Bank estimate)", "social_labor_protec"="Adequacy of social protection and labor programs (% of total welfare of beneficiary households)", "social_safety_net"="Adequacy of social safety net programs (% of total welfare of beneficiary households)", "social_insurance_coverage"="Coverage of social insurance programs (% of population)",  "social_safety_coverage"="Coverage of social safety net programs (% of population)",  "multi_pov"="Multidimensional poverty headcount ratio (% of total population)", "multi_pov_child"="Multidimensional poverty headcount ratio, children (% of population ages 0-17)")

```



# creation of cv folds

```{r}
set.seed(321)
lifeexpectancy_cv7 <- vfold_cv(lifeExpectancy, v = 7)
```


```{r}
# model spec
lm_spec <- 
    linear_reg() %>% 
    set_engine(engine = 'lm') %>% 
    set_mode('regression') 

lm_lasso_spec <- 
  linear_reg() %>%
  set_args(mixture = 1, penalty = 0) %>%
  set_engine(engine = 'glmnet') %>%
  set_mode('regression') 
```

```{r}
# recipes & workflows

## I think we need a non-lasso recipe and wf here?


life_rec<-recipe(`life_expec` ~ ., data = lifeExpectancy) %>% 
    step_lincomb(all_numeric_predictors()) %>% 
    step_nzv(all_numeric_predictors()) %>%
    step_unknown(all_nominal_predictors()) 

#<<<<<<< HEAD
life_model_wf <- workflow() %>%
  add_recipe(life_rec) %>% 
  add_model(lm_spec)
#=======
#life_rec_wf <- workflow() %>%
  #add_recipe(life_rec) %>%
#>>>>>>> 09e5eebf78b0d44b0a83a167af1e12579c9ed2a9
  #add_model(lm_spec)

#this is the chunk of code not working
lasso_fit_rec <- life_model_wf %>% 
  fit(data =lifeExpectancy) 

 
```

```{r}
#fit & tune models


## fit the non-lasso model?



lm_lasso_spec_tune <- 
  linear_reg() %>%
  set_args(mixture = 1, penalty = tune()) %>%
  set_engine(engine = 'glmnet') %>%
  set_mode('regression') 

#I don't think we need this since we wf the model in a previous code chunk
lasso_wf_lifeex <- workflow() %>% 
  add_recipe(life_rec) %>%
  add_model(lm_lasso_spec_tune) 

penalty_grid <- grid_regular(
  penalty(range = c(-5, 3)), #log10 transformed 10^-5 to 10^3
  levels = 50)


# I tihnk we have to change something here.. or lots of somethings
tune_res <- tune_grid( 
  lasso_wf_lifeex,
  resamples = lifeexpectancy_cv7,
  metrics = metric_set(rmse),
  grid = penalty_grid
)

#here's where the code doesn't run (ln. 300)
autoplot(tune_res)

collect_metrics(tune_res) %>%
  filter(.metric == 'rmse') %>%
  select(penalty, rmse = mean) 


best_penalty <- select_best(tune_res, metric = 'rmse') # choose best penalty value

life_final_wk <- finalize_workflow(lasso_wf_lifeex, best_penalty) # incorporates penalty value to workflow

lifeex_final_fit <- fit(Credit_final_wk, data = lifeExpectancyData)

tidy(Credit_final_fit)

```

c.

```{r}
#  calculate/collect CV metrics
mod_final %>% collect_metrics()
```


```{r}
## I don't think we need any of this, saving it anyways cause we might need for our first model???


full_model <- fit(lm_spec,
             ~ .,  # The . means all predictors
            data = bodyfat_train) 

fit(lm_spec,
  fatSiri ~ . - hip,  
  data = bodyfat_train) %>% 
  tidy() %>%
  arrange(desc(p.value))

fit(lm_spec,
  fatSiri ~ . - hip - chest,  
  data = bodyfat_train) %>% 
  tidy() %>%
  arrange(desc(p.value))


fit(lm_spec,
  fatSiri ~ . - hip - chest - height,  
  data = bodyfat_train) %>% 
  tidy() %>%
  arrange(desc(p.value))

full_model %>% tidy() %>% arrange(desc(p.value))
```


d.

```{r}
# visual residuals
#  Residuals vs. predictions
ggplot(mod1_output, aes(x = .pred, y = resid)) +
    geom_point() +
    geom_smooth() +
    geom_hline(yintercept = 0, color = "red") +
    theme_classic()
# Residuals vs. predictors (x's)
 
ggplot(mod1_output, aes(x = height, y = resid)) +
    geom_point() +
    geom_smooth() +
    geom_hline(yintercept = 0, color = "red") +
    theme_classic()
```

e.

<br>

2. **Summarize investigations**
    - Decide on an overall best model based on your investigations so far. To do this, make clear your analysis goals. Predictive accuracy? Interpretability? A combination of both?

Our analysis is more focused on interpretability than predictive accuracy as we are interested in which of our predictor variables have the greatest impact on a country's average life expectancy rather than, for example, trying to predict a country's average life expectancy based on various socioeconomic factors. This is not only because the first approach is more useful but also because the latter is an ineffective way of trying to accomplish its goal.

<br>

3. **Societal impact**
    - Are there any harms that may come from your analyses and/or how the data were collected?
    - What cautions do you want to keep in mind when communicating your work?

Using an OLS to evaluate life expectancy in 1 year does make it easier to draw conclusions however, makes the data very simple and eliminates nuances. For example, 
by only using data from 1 year, we can't draw broad conclusions about the data over time. The predictors that we've selected may actually be expletive 
of what impacts life expectancy around the world. Another nuance that our analysis may miss is the importance of societal norms, gender roles, cultural context and geographic disparities that may make our estimation of the life expectancy inaccurate. Some of the cautions that we want to keep in mind are the year that we are working in and possible externalities that are impacting our results.  

<br><br><br>



## Portfolio Work {-}

**Length requirements:** Detailed for each section below.

**Organization:** To help the instructor and preceptors grade, please organize your document with clear section headers and start new pages for each method. Thank you!

**Deliverables:** Continue writing your responses in the same Google Doc that you set up for Homework 1. Include that URL for the Google Doc in your submission.

**Note:** Some prompts below may seem very open-ended. This is intentional. Crafting good responses requires looking back through our material to organize the concepts in a coherent, thematic way, which is extremely useful for your learning.

<br>

**Revisions:**

- Make any revisions desired to previous concepts. **Important note:** When making revisions, please change from "editing" to "suggesting" so that we can easily see what you've added to the document since we gave feedback (we will "accept" the changes when we give feedback). If you don't do this, we won't know to reread that section and give new feedback.

- General guideance for past homeworks will be available on Moodle (under the Solutions section). Look at these to guide your revisions. You can always ask for guidance in office hours as well.

<br>

**New concepts to address:**

- **Subset selection:**
    - Algorithmic understanding: Look at Conceptual exercise 1, parts (a) and (b) in ISLR Section 6.8. **What are the aspects of the subset selection algorithm(s) that are essential to answering these questions, and why?** (Note: you'll have to try to answer the ISLR questions to respond to this prompt, but the focus of your writing should be on the question in bold here.)
    - Bias-variance tradeoff: What "tuning parameters" control the performance of this method? How do low/high values of the tuning parameters relate to bias and variance of the learned model? (3 sentences max.)
    - Parametric / nonparametric:  Where (roughly) does this method fall on the parametric-nonparametric spectrum, and why? (3 sentences max.)
    - Scaling of variables: Does the scale on which variables are measured matter for the performance of this algorithm? Why or why not? If scale does matter, how should this be addressed when using this method? (3 sentences max.)
    - Computational time: What computational time considerations are relevant for this method (how long the algorithms take to run)?
    - Interpretation of output: What parts of the algorithm output have useful interpretations, and what are those interpretations? **Focus on output that allows us to measure variable importance. How do the algorithms/output allow us to learn about variable importance?**

- **LASSO:**
    - Algorithmic understanding: Come up with your own analogy for explaining how the penalized least squares criterion works.
    - Bias-variance tradeoff: What tuning parameters control the performance of this method? How do low/high values of the tuning parameters relate to bias and variance of the learned model? (3 sentences max.)
    - Parametric / nonparametric: Where (roughly) does this method fall on the parametric-nonparametric spectrum, and why? (3 sentences max.)
    - Scaling of variables: Does the scale on which variables are measured matter for the performance of this algorithm? Why or why not? If scale does matter, how should this be addressed when using this method? (3 sentences max.)
    - Computational time: What computational time considerations are relevant for this method (how long the algorithms take to run)?
    - Interpretation of output: What parts of the algorithm output have useful interpretations, and what are those interpretations? **Focus on output that allows us to measure variable importance. How do the algorithms/output allow us to learn about variable importance?**


- **KNN:**
    - Algorithmic understanding: Draw and annotate pictures that show how the KNN (K = 2) regression algorithm would work for a test case in a 2 quantitative predictor setting. Also explain how the curse of dimensionality affects KNN performance. (5 sentences max.)
    - Bias-variance tradeoff: What tuning parameters control the performance of this method? How do low/high values of the tuning parameters relate to bias and variance of the learned model? (3 sentences max.)
    - Parametric / nonparametric: Where (roughly) does this method fall on the parametric-nonparametric spectrum, and why? (3 sentences max.)
    - Scaling of variables: Does the scale on which variables are measured matter for the performance of this algorithm? Why or why not? If scale does matter, how should this be addressed when using this method? (3 sentences max.)
    - Computational time: The KNN algorithm is often called a "lazy" learner. Discuss how this relates to the model training process and the computations that must be performed when predicting on a new test case. (3 sentences max.)
    - Interpretation of output: The "lazy" learner feature of KNN in relation to model training affects the interpretability of output. How? (3 sentences max.)

<br><br><br>



## Reflection {-}

**Ethics: ** Read the article [Automated background checks are deciding who's fit for a home](https://www.theverge.com/platform/amp/2019/2/1/18205174/automation-background-check-criminal-records-corelogic). Write a short (roughly 250 words), thoughtful response about the ideas that the article brings forth. What themes recur from last week's article (on an old Amazon recruiting tool) or movie (Coded Bias)? What aspects are more particular to the context of equity in housing access?


**Reflection:** Write a short, thoughtful reflection about how things went this week. Feel free to use whichever prompts below resonate most with you, but don't feel limited to these prompts.

- How are class-related things going? Is there anything that you need from the instructor? What new strategies for watching videos, reading, reviewing, gaining insights from class work have you tried or would like to try?
- How is group work going? Did you try out any new collaboration strategies with your new group? How did they go?
- How is your work/life balance going? Did you try out any new activities or strategies for staying well? How did they go?


**Self-Assessment:** Before turning in this assignment on Moodle, go to the individual rubric shared with you and complete the self-assessment for the general skills (top section). After "HW2:", assess yourself on each of the general skills. Do feel like you've grown in a particular area since HW1?

Assessing yourself is hard. We must practice this skill. These "grades" you give yourself are intended to have you stop and think about your learning as you grow and develop the general skills and deepen your understanding of the course topics. These grades do not map directly to a final grade. 

